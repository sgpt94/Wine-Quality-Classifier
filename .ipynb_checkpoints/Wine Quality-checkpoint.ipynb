{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Quality Classification \n",
    "### Using Logistic Regression and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting \"Quality\" in 0 and 1\n",
    "#### (Quality > 6.5) --> 1, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.170</td>\n",
       "      <td>51.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.092</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.341</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0             7.4             0.700         0.00             1.9      0.076   \n",
       "1             7.8             0.880         0.00             2.6      0.098   \n",
       "2             7.8             0.760         0.04             2.3      0.092   \n",
       "3            11.2             0.280         0.56             1.9      0.075   \n",
       "4             7.4             0.700         0.00             1.9      0.076   \n",
       "5             7.4             0.660         0.00             1.8      0.075   \n",
       "6             7.9             0.600         0.06             1.6      0.069   \n",
       "7             7.3             0.650         0.00             1.2      0.065   \n",
       "8             7.8             0.580         0.02             2.0      0.073   \n",
       "9             7.5             0.500         0.36             6.1      0.071   \n",
       "10            6.7             0.580         0.08             1.8      0.097   \n",
       "11            7.5             0.500         0.36             6.1      0.071   \n",
       "12            5.6             0.615         0.00             1.6      0.089   \n",
       "13            7.8             0.610         0.29             1.6      0.114   \n",
       "14            8.9             0.620         0.18             3.8      0.176   \n",
       "15            8.9             0.620         0.19             3.9      0.170   \n",
       "16            8.5             0.280         0.56             1.8      0.092   \n",
       "17            8.1             0.560         0.28             1.7      0.368   \n",
       "18            7.4             0.590         0.08             4.4      0.086   \n",
       "19            7.9             0.320         0.51             1.8      0.341   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                  25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                  15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                  17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                  11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                  13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                  15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                  15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                   9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                  17.0                 102.0   0.9978  3.35       0.80   \n",
       "10                 15.0                  65.0   0.9959  3.28       0.54   \n",
       "11                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "12                 16.0                  59.0   0.9943  3.58       0.52   \n",
       "13                  9.0                  29.0   0.9974  3.26       1.56   \n",
       "14                 52.0                 145.0   0.9986  3.16       0.88   \n",
       "15                 51.0                 148.0   0.9986  3.17       0.93   \n",
       "16                 35.0                 103.0   0.9969  3.30       0.75   \n",
       "17                 16.0                  56.0   0.9968  3.11       1.28   \n",
       "18                  6.0                  29.0   0.9974  3.38       0.50   \n",
       "19                 17.0                  56.0   0.9969  3.04       1.08   \n",
       "\n",
       "    alcohol  quality  \n",
       "0       9.4        0  \n",
       "1       9.8        0  \n",
       "2       9.8        0  \n",
       "3       9.8        0  \n",
       "4       9.4        0  \n",
       "5       9.4        0  \n",
       "6       9.4        0  \n",
       "7      10.0        1  \n",
       "8       9.5        1  \n",
       "9      10.5        0  \n",
       "10      9.2        0  \n",
       "11     10.5        0  \n",
       "12      9.9        0  \n",
       "13      9.1        0  \n",
       "14      9.2        0  \n",
       "15      9.2        0  \n",
       "16     10.5        1  \n",
       "17      9.3        0  \n",
       "18      9.0        0  \n",
       "19      9.2        0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['quality'] <= 6.5,'quality'] = 0\n",
    "df.loc[df['quality'] > 6.5 , 'quality'] = 1\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1382\n",
       "1     217\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.570981863664791\n"
     ]
    }
   ],
   "source": [
    "percent_good = (df.loc[df['quality']==1,'quality'].count()/df['quality'].count())*100\n",
    "percent_bad = 100 - percent_good\n",
    "print(percent_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x13b187b2250>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(df,col = 'quality' )\n",
    "g.map_dataframe(sns.histplot, x=\"fixed acidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x13b184f1460>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(df,col = 'quality' )\n",
    "g.map_dataframe(sns.histplot, x=\"alcohol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x13b18993a00>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(df,col = 'quality' )\n",
    "g.map_dataframe(sns.histplot, x=\"pH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference From hist plot\n",
    "Fixed acidity and alcohol content are higher in good quality wines <br />\n",
    "pH is more or less same in good and bad quality wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 12), (1599, 11), (1599,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('quality',axis=1)\n",
    "y = df['quality']\n",
    "X.head()\n",
    "df.shape,X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.059</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.99686</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.088</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "423            10.5             0.240         0.47             2.1      0.066   \n",
       "685             8.1             0.780         0.23             2.6      0.059   \n",
       "1199            7.9             0.580         0.23             2.3      0.076   \n",
       "600             8.2             0.915         0.27             2.1      0.088   \n",
       "822             6.7             0.540         0.13             2.0      0.076   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "423                   6.0                  24.0  0.99780  3.15       0.90   \n",
       "685                   5.0                  15.0  0.99700  3.37       0.56   \n",
       "1199                 23.0                  94.0  0.99686  3.21       0.58   \n",
       "600                   7.0                  23.0  0.99620  3.26       0.47   \n",
       "822                  15.0                  36.0  0.99730  3.61       0.64   \n",
       "\n",
       "      alcohol  \n",
       "423      11.0  \n",
       "685      11.3  \n",
       "1199      9.5  \n",
       "600      10.0  \n",
       "822       9.8  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 11), (480, 11), (1119,), (480,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    967\n",
       " 1    152\n",
       " Name: quality, dtype: int64,\n",
       " 0    415\n",
       " 1     65\n",
       " Name: quality, dtype: int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(),y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645833333333334\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395  20]\n",
      " [ 45  20]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       415\n",
      "           1       0.50      0.31      0.38        65\n",
      "\n",
      "    accuracy                           0.86       480\n",
      "   macro avg       0.70      0.63      0.65       480\n",
      "weighted avg       0.84      0.86      0.85       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 453, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\shashank\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.535075 using {'C': 0.001291549665014884, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['none','l1','l2']\n",
    "c_range = np.logspace(-4,1,10)\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_range)\n",
    "grid_search = GridSearchCV(estimator=logreg,param_grid=grid,scoring='f1')\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression(penalty='l2',C=0.0012,solver='liblinear',random_state=0).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86875\n"
     ]
    }
   ],
   "source": [
    "pred = clf2.predict(X_test)\n",
    "score = clf2.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       415\n",
      "           1       0.52      0.43      0.47        65\n",
      "\n",
      "    accuracy                           0.87       480\n",
      "   macro avg       0.72      0.68      0.70       480\n",
      "weighted avg       0.86      0.87      0.86       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       415\n",
      "           1       0.72      0.32      0.45        65\n",
      "\n",
      "    accuracy                           0.89       480\n",
      "   macro avg       0.81      0.65      0.69       480\n",
      "weighted avg       0.88      0.89      0.87       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035070785070787"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_eval = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
